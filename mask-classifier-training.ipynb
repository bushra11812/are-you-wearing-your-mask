{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from scipy import ndimage, misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"labels/save.txt\", engine=\"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = {}\n",
    "ppl = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = len(labels)\n",
    "\n",
    "for i in range (num):\n",
    "    dic[labels[\"id\"][i]] = labels[\"class\"][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dispcf(X,Y):\n",
    "    \n",
    "    predictions = model.predict(X)\n",
    "    pred_lbls   = np.argmax(predictions, axis=1)\n",
    "\n",
    "    true0,false0,true1,false1,true2,false2 = 0,0,0,0,0,0\n",
    "\n",
    "    for i in range (len(pred_lbls)):\n",
    "        if pred_lbls[i] == np.argmax(Y[i]):\n",
    "            if pred_lbls[i] == 0:\n",
    "                true0 += 1\n",
    "            elif pred_lbls[i] == 1:\n",
    "                true1 += 1 \n",
    "            elif pred_lbls[i] == 2:\n",
    "                true2 += 1 \n",
    "        else:\n",
    "            if pred_lbls[i] == 0:\n",
    "                false0 += 1\n",
    "            elif pred_lbls[i] == 1:\n",
    "                false1 += 1 \n",
    "            elif pred_lbls[i] == 2:\n",
    "                false2 += 1 \n",
    "\n",
    "    print(\"true0:{}\\tfalse0:{}\\ntrue1:{}\\tfalse1:{}\".format(true0,false0,true1,false1)) \n",
    "    \n",
    "    return (1-(true0*false1)/(true1*false0))**2\n",
    "\n",
    "def shift_image(X, dx, dy):\n",
    "    X = np.roll(X, dy, axis=0)\n",
    "    X = np.roll(X, dx, axis=1)\n",
    "    if dy>0:\n",
    "        X[:dy, :] = X[dy:dy*2, :]\n",
    "    elif dy<0:\n",
    "        X[dy:, :] = X[dy*2:dy, :]\n",
    "    if dx>0:\n",
    "        X[:, :dx] = X[:,dx:dx*2]\n",
    "    elif dx<0:\n",
    "        X[:, dx:] = X[:, dx*2:dx]\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = 32,32\n",
    "\n",
    "\n",
    "for i in dic.keys():\n",
    "    \n",
    "    vals.append(dic[i])\n",
    "    \n",
    "    img = Image.open(\"peep/p{:06d}.jpg\".format(i))\n",
    "    width, height = img.size\n",
    "\n",
    "    left = width/4\n",
    "    top = 10\n",
    "    right = 3*width/4\n",
    "    bottom = height/2\n",
    "    crp = img.crop((left, top, right, bottom)).resize((x,y))\n",
    "    \n",
    "    ppl.append(np.array(crp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(vals,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vals), len(ppl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPSAMPLING MEANINGFUL DATA\n",
    "\n",
    "for i in range (len(vals)):\n",
    "    if vals[i]!=2:\n",
    "        ppl.append(np.flip(ppl[i], axis=1))\n",
    "        vals.append(vals[i])\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (len(vals)):\n",
    "    if vals[i]==2:\n",
    "        vals[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(vals)\n",
    "\n",
    "norm_coeff = (np.average(vals)**-1)\n",
    "print(norm_coeff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALIZATION\n",
    "\n",
    "# PS: If no normalization is done at first, the model newer learns to differentiate between\n",
    "# masked and non-masked people. At first, we normalize the input. But after several iterations,\n",
    "# I gradually trained the model with less normalized data, decreasing `norm_coeff`.\n",
    "# \n",
    "# I recommend commenting out the model declaration and rerun all cells after each decrease in `norm_coeff`.\n",
    "# This can of course be automated, but I liked to have control over the training process.\n",
    "\n",
    "for i in range (len(vals)):\n",
    "    if vals[i]==1:\n",
    "        for j in range(int(norm_coeff)):\n",
    "            npl = shift_image(ppl[i],j,j)\n",
    "            rpl = ndimage.rotate(npl, j, mode=\"mirror\",reshape=False)\n",
    "            ppl.append(rpl)\n",
    "            vals.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppl = np.array(ppl)\n",
    "vals = np.array(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram with twice as much masked people\n",
    "plt.hist(vals,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "# using naive method \n",
    "# Separating odd and even index elements \n",
    "ppl_train  = [] \n",
    "ppl_test   = []\n",
    "vals_train = [] \n",
    "vals_test  = []\n",
    "\n",
    "for i in range(0, len(ppl)): \n",
    "    if i % 8: \n",
    "        ppl_train.append(ppl[i]) \n",
    "        vals_train.append(vals[i])\n",
    "    else : \n",
    "        ppl_test.append(ppl[i]) \n",
    "        vals_test.append(vals[i])\n",
    "        \n",
    "ppl_train  = np.array(ppl_train)\n",
    "ppl_test   = np.array(ppl_test)\n",
    "vals_train = np.array(vals_train)\n",
    "vals_test  = np.array(vals_test)\n",
    "\n",
    "ppl_train, vals_train = shuffle(ppl_train, vals_train)\n",
    "ppl_test,  vals_test  = shuffle(ppl_test,  vals_test)\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\"balanced\", np.unique(vals_train), vals_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "class_weight_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras imports for the dataset and building our neural network\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten, BatchNormalization, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# to calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# loading the dataset\n",
    "X_train = ppl_train\n",
    "X_test  = ppl_test\n",
    "\n",
    "y_train = vals_train\n",
    "y_test  = vals_test\n",
    "\n",
    "\n",
    "# building the input vector from the 28x28 pixels\n",
    "#X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "#X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = len(np.unique(vals))\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "# convolutional layer\n",
    "model.add(Conv2D(64, kernel_size=(5,5), strides=(1,1), activation='relu', input_shape=(x,y,3)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(x,y,3)))\n",
    "model.add(Dropout(.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# flatten output of conv\n",
    "model.add(Flatten())\n",
    "# hidden layer\n",
    "model.add(Dense(48, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='binary_crossentropy', metrics=['binary_accuracy'], optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess.run([\"mkdir\", \"modelchkpts\"])\n",
    "checkpoint = ModelCheckpoint('modelchkpts/model-{epoch:03d}-{val_binary_accuracy:06f}.h5', verbose=1, monitor='val_binary_accuracy',save_best_only=True, mode='auto')  \n",
    "\n",
    "for i in range(300):\n",
    "    # training the model for 10 epochs\n",
    "    model.fit(X_train, Y_train, \n",
    "                        batch_size=128, \n",
    "                        epochs=1,\n",
    "                        shuffle=True, \n",
    "                        class_weight=class_weight_dict, \n",
    "                        callbacks=[checkpoint],\n",
    "                        validation_data=(X_test, Y_test))\n",
    "    prs = np.argmax(model.predict(pred_ppl), axis=1)\n",
    "    print(prs)\n",
    "    try:\n",
    "        dispcf(X_test, Y_test)\n",
    "    except:\n",
    "        pass "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
