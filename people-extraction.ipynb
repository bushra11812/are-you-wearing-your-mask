{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlink\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import imagehash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxi_color = [12,196,214]\n",
    "taxis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_duplicates = {}\n",
    "\n",
    "class dupinstance:\n",
    "    def __init__(self, img):\n",
    "        self.img   = img\n",
    "        self.birth = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# misc functions\n",
    "\n",
    "def cv2resize(img, scale_percent):\n",
    "    \n",
    "    width = int(img.shape[1] * scale_percent / 100)\n",
    "    height = int(img.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    # resize image\n",
    "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    return resized\n",
    "\n",
    "\n",
    "def compare(enum, im1, im2):\n",
    "    \n",
    "    nim2 = cv2.resize(im2, (im1.shape[1],im1.shape[0]))\n",
    "    \n",
    "    im_v = cv2.hconcat([im1, nim2])\n",
    "    \n",
    "    diff_ = np.sum(np.square(nim2-im1))/(im1.shape[0]*im1.shape[2])\n",
    "    diff  = imagehash.average_hash(Image.fromarray(nim2))-imagehash.average_hash(Image.fromarray(im1))\n",
    "    \n",
    "    #cv2.imwrite(\"pairs/comparison/c{}_{}.jpg\".format(repr(diff).replace(\".\", \"x\"), repr(int(diff_//1)).replace(\".\", \"x\")), im_v)\n",
    "    \n",
    "    if diff_ < 6400 and diff < 15:\n",
    "        #cv2.imwrite(\"pairs/similar/d{:06d}_{}_{}.jpg\".format(int(diff//1), int(time.time()//1), enum), im_v)\n",
    "        return \"similar\"\n",
    "    elif diff_ < 6900 and diff < 21:\n",
    "        #cv2.imwrite(\"pairs/different/d{:06d}_{}_{}.jpg\".format(int(diff//1), int(time.time()//1), enum), im_v)\n",
    "        return \"ambigous\"\n",
    "    else:\n",
    "        return \"different\"\n",
    "    \n",
    "    \n",
    "def taxi_score(img, threshold = 500):\n",
    "    \n",
    "    count  = 0\n",
    "    color_br = np.ones(img.shape)*taxi_color\n",
    "\n",
    "    for row in range (img.shape[0]):\n",
    "        for col in range (img.shape[1]):\n",
    "            if np.mean(np.square(img[row, col] - color_br[row, col])) < threshold:\n",
    "                count+=1\n",
    "\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from streamlink import Streamlink\n",
    "\n",
    "session = Streamlink()\n",
    "\n",
    "session.set_option(\"http-ssl-verify\", False)\n",
    "\n",
    "# https://livestream.ibb.gov.tr/ibb_live/istiklalcad2hq.stream/Playlist.m3u8\n",
    "# https://livestream.ibb.gov.tr/ibb_live/misircarsisihq.stream/chunklist_w289409329.m3u8\n",
    "# https://livestream.ibb.gov.tr/ibb_live/istiklalcadhq.stream/Playlist.m3u8\n",
    "\n",
    "streams = session.streams(\"https://livestream.ibb.gov.tr/ibb_live/istiklalcad2hq.stream/Playlist.m3u8\")\n",
    "stream = streams[\"worst\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_type = \"person\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if detection_type == \"person\":\n",
    "    # initialize the HOG descriptor/person detector\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    hog.setSVMDetector(cv2.HOGDescriptor_getDefaultPeopleDetector())\n",
    "    \n",
    "elif detection_type == \"face\":\n",
    "    # Load the cascade for face detector\n",
    "    cascade = cv2.CascadeClassifier('models/haarcascade_frontalface_default.xml')\n",
    "    \n",
    "elif detection_type == \"head\":\n",
    "    # Load the cascade for face detector\n",
    "    cascade = cv2.CascadeClassifier('models/cascadeHead5.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enum = 0\n",
    "pnum = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peep = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cv2.startWindowThread()\n",
    "\n",
    "# open webcam video stream\n",
    "cap = cv2.VideoCapture(stream.url)\n",
    "\n",
    "# the output will be written to output.avi\n",
    "out_md = cv2.VideoWriter(\n",
    "    'output.avi',\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    15.,\n",
    "    (640,480))\n",
    "out_cl = cv2.VideoWriter(\n",
    "    'clean.avi',\n",
    "    cv2.VideoWriter_fourcc(*'MJPG'),\n",
    "    15.,\n",
    "    (640,480))\n",
    "\n",
    "to_be_deleted_dc = []\n",
    "\n",
    "while(True):\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "\n",
    "    # resizing for faster detection\n",
    "    frame = cv2.resize(frame, (640, 480))\n",
    "\n",
    "    if crop:\n",
    "        #crop top half\n",
    "        crop_frame = frame[240:480, 0:640]\n",
    "        frame = crop_frame\n",
    "\n",
    "    # make a clean copy of the frame (cv2 images are copied by reference)\n",
    "    frame_clean = frame.copy()\n",
    "\n",
    "    if detection_type == \"person\":\n",
    "\n",
    "        # using a greyscale picture, also for faster detection\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        # detect people in the image\n",
    "        # returns the bounding boxes for the detected objects\n",
    "        boxes, weights = hog.detectMultiScale(frame, winStride=(8,8) )\n",
    "\n",
    "    elif detection_type == \"face\":\n",
    "\n",
    "        # Convert into grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect faces\n",
    "        boxes = cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    elif detection_type == \"head\":\n",
    "\n",
    "        # Convert into grayscale\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # Detect faces\n",
    "        boxes = cascade.detectMultiScale(gray, 1.1, 4)\n",
    "\n",
    "    boxes = np.array([[x, y, x + w, y + h] for (x, y, w, h) in boxes])\n",
    "\n",
    "    for (xA, yA, xB, yB) in boxes:\n",
    "\n",
    "        # display the detected boxes in the colour picture\n",
    "        cv2.rectangle(frame, (xA, yA), (xB, yB), (0, 0, 0), 2)\n",
    "\n",
    "        #get contents of the bounding box\n",
    "        box = frame_clean[yA:yB, xA:xB]\n",
    "        \n",
    "        #how much does this image contain the color of a taxi?\n",
    "        #this is an attempt to get rid of many yellow taxis that get recognized as people\n",
    "        taximeter = taxi_score(box, 630)\n",
    "        if taximeter > 180:\n",
    "            taxis.append(box)\n",
    "            continue\n",
    "\n",
    "\n",
    "        isUnique   = True #until proven not\n",
    "        isAmbigous = False\n",
    "\n",
    "        #iterate through the dictionary containing possible duplicates.   \n",
    "        for key, item in possible_duplicates.items():\n",
    "\n",
    "            #if duplicate candidate is 2 minutes old, schedule to delete it (can't change dic size during iteration).\n",
    "            if time.time()-item.birth > 30:\n",
    "                    to_be_deleted_dc.append(key)\n",
    "                    \n",
    "        #iterate through the dictionary containing possible duplicates.   \n",
    "        for key, item in possible_duplicates.items():\n",
    "\n",
    "            #if the new box is already in duplicates, don't save it as a unique person.\n",
    "            similarity = compare(enum, box, item.img)\n",
    "            if(similarity == \"similar\"):\n",
    "                #instead update the duplicate candidate with its newer version.\n",
    "                possible_duplicates[key] = dupinstance(box)\n",
    "                isUnique = False\n",
    "                continue\n",
    "                \n",
    "            elif(similarity == \"ambigous\"):\n",
    "                isAmbigous = True\n",
    "                isUnique = False\n",
    "\n",
    "\n",
    "        # delete old dcs\n",
    "        for key in to_be_deleted_dc:\n",
    "            if(key in possible_duplicates.keys()):\n",
    "                del possible_duplicates[key]\n",
    "\n",
    "        to_be_deleted_dc.clear()\n",
    "        \n",
    "\n",
    "        # if its unique, save it as a unique person.\n",
    "        if isUnique:\n",
    "            cv2.imwrite(\"peep/p{:06d}.jpg\".format(pnum), box)\n",
    "            peep.append(box)\n",
    "            possible_duplicates[enum] = dupinstance(box)\n",
    "            enum+=1\n",
    "            pnum+=1\n",
    "        \n",
    "        if isAmbigous:\n",
    "            #instead update the duplicate candidate with its newer version.\n",
    "            possible_duplicates[enum] = dupinstance(box)\n",
    "            enum += 1\n",
    "\n",
    "    # Write the output video \n",
    "    # out_md.write(frame.astype('uint8'))\n",
    "    out_cl.write(frame_clean.astype('uint8'))\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('mask-detector',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "            \n",
    "# When everything done, release the capture\n",
    "cap.release()\n",
    "# and release the output\n",
    "out.release()\n",
    "# finally, close the window\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
